{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rasathuraikaran/BabyCare/blob/main/imageprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get grey scale image**"
      ],
      "metadata": {
        "id": "IUmFEZtDqQMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def process_image(input_path, output_path, new_dimensions):\n",
        "    # Load the image using PIL\n",
        "    image = Image.open(input_path)\n",
        "\n",
        "    # Resize the image to the desired dimensions\n",
        "    resized_image = image.resize(new_dimensions)\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray_image = resized_image.convert('L')\n",
        "\n",
        "    # Convert the grayscale image to double precision\n",
        "    gray_image_np = np.array(gray_image, dtype=np.float64)\n",
        "\n",
        "    # Save the grayscale image as JPEG\n",
        "    gray_image.save(output_path, 'JPEG')\n",
        "\n",
        "    # Get the dimensions of the grayscale image\n",
        "    width, height = gray_image.size\n",
        "\n",
        "    # Display the dimensions\n",
        "    print(f\"Image Dimensions: {width} x {height}\")\n",
        "    print(f\"Output Path: {output_path}\")\n",
        "\n",
        "# Example usage\n",
        "input_path = '/content/image3.jpeg'\n",
        "output_path = '/content/gray_image.jpg'\n",
        "new_dimensions = (1920, 1080)\n",
        "\n",
        "process_image(input_path, output_path, new_dimensions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "4OIYVxwnTFl7",
        "outputId": "15ccce3d-2de1-40ef-cec0-cedee6cdc54b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/image3.jpeg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-54a7cc4f0078>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mnew_dimensions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1920\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1080\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_dimensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-54a7cc4f0078>\u001b[0m in \u001b[0;36mprocess_image\u001b[0;34m(input_path, output_path, new_dimensions)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_dimensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Load the image using PIL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Resize the image to the desired dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3226\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3227\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3228\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/image3.jpeg'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get DCT of image**"
      ],
      "metadata": {
        "id": "PudTmUY6qaa9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and process the image\n",
        "input_path = '/content/image3.jpeg'\n",
        "output_path = '/content/gray_image.jpg'\n",
        "new_dimensions = (1920, 1080)\n",
        "\n",
        "# Process the image to grayscale\n",
        "process_image(input_path, output_path, new_dimensions)\n",
        "\n",
        "# Load the grayscale image into an array\n",
        "gray_image = Image.open(output_path)\n",
        "gray_image_np = np.array(gray_image, dtype=np.float64)\n",
        "\n",
        "# Apply DCT to the entire image (by blocks)\n",
        "dct_image = apply_dct_to_blocks(gray_image_np)\n",
        "\n",
        "# Display and save the DCT image\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(dct_image, cmap='gray', vmax=np.max(dct_image)*0.01, vmin=0)\n",
        "plt.title('DCT of the image')\n",
        "plt.colorbar()\n",
        "\n",
        "# Save the DCT image\n",
        "dct_output_path = '/content/dct_image.jpg'\n",
        "plt.imsave(dct_output_path, dct_image, cmap='gray', vmax=np.max(dct_image)*0.01, vmin=0)\n",
        "\n",
        "# Display the DCT output path\n",
        "dct_output_path\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "RMOcHJwNTUsP",
        "outputId": "c2302c5f-e31c-4162-ce1e-8a9777e22236"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/image3.jpeg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-70c9b3b74cf2>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Process the image to grayscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_dimensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Load the grayscale image into an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-54a7cc4f0078>\u001b[0m in \u001b[0;36mprocess_image\u001b[0;34m(input_path, output_path, new_dimensions)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_dimensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Load the image using PIL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Resize the image to the desired dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3226\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3227\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3228\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/image3.jpeg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define a custom quantization matrix for JPEG compression\n",
        "custom_quantization_matrix = np.array([[16, 11, 10, 16, 24, 40, 51, 61],\n",
        "                                       [12, 12, 14, 19, 26, 58, 60, 55],\n",
        "                                       [14, 13, 16, 24, 40, 57, 69, 56],\n",
        "                                       [14, 17, 22, 29, 51, 87, 80, 62],\n",
        "                                       [18, 22, 37, 56, 68, 109, 103, 77],\n",
        "                                       [24, 35, 55, 64, 81, 104, 113, 92],\n",
        "                                       [49, 64, 78, 87, 103, 121, 120, 101],\n",
        "                                       [72, 92, 95, 98, 112, 100, 103, 99]])\n",
        "\n",
        "# Function to quantize DCT blocks based on a specified quality factor\n",
        "def custom_quantize_dct_blocks(dct_blocks, quality_factor=1):\n",
        "    # Adjust the quantization matrix based on quality factor\n",
        "    scaled_quantization_matrix = custom_quantization_matrix * quality_factor\n",
        "\n",
        "    # Get the dimensions of the DCT blocks\n",
        "    height, width = dct_blocks.shape\n",
        "    quantized_blocks = np.zeros_like(dct_blocks)\n",
        "\n",
        "    i = 0\n",
        "    while i < height:\n",
        "        j = 0\n",
        "        while j < width:\n",
        "            # Extract the current 8x8 block\n",
        "            current_block = dct_blocks[i:i+8, j:j+8]\n",
        "\n",
        "            # Quantize the block by dividing by the scaled quantization matrix\n",
        "            quantized_block = np.round(current_block / scaled_quantization_matrix)\n",
        "\n",
        "            # Assign the quantized block back to its position\n",
        "            quantized_blocks[i:i+8, j:j+8] = quantized_block\n",
        "\n",
        "            j += 8  # Move to the next block horizontally\n",
        "\n",
        "        i += 8  # Move to the next block vertically\n",
        "\n",
        "    return quantized_blocks\n",
        "\n",
        "# Example usage\n",
        "# Assuming that 'dct_image' is already defined\n",
        "quantized_low_quality = custom_quantize_dct_blocks(dct_image, quality_factor=3)  # Applying lower quality quantization\n",
        "quantized_medium_quality = custom_quantize_dct_blocks(dct_image, quality_factor=2.5)  # Applying medium quality quantization\n",
        "quantized_high_quality = custom_quantize_dct_blocks(dct_image, quality_factor=2)  # Applying higher quality quantization\n",
        "\n",
        "# You can then save or process these quantized blocks as needed\n"
      ],
      "metadata": {
        "id": "6i4zSUq-U_vT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quantized_low_quality"
      ],
      "metadata": {
        "id": "aAy_qhhuWJJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quantized_medium_quality"
      ],
      "metadata": {
        "id": "eKzwmtODWM6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quantized_high_quality"
      ],
      "metadata": {
        "id": "GR2W9wNkj5i9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import heapq\n",
        "from collections import defaultdict\n",
        "\n",
        "# Step 1: Generate frequency table\n",
        "def calculate_frequency(data):\n",
        "    frequency_table = defaultdict(int)\n",
        "    for val in data.flatten():\n",
        "        frequency_table[val] += 1\n",
        "    return frequency_table\n",
        "\n",
        "# Step 2: Build Huffman Tree\n",
        "def construct_huffman_tree(frequency_table):\n",
        "    heap = [[weight, [symbol, \"\"]] for symbol, weight in frequency_table.items()]\n",
        "    heapq.heapify(heap)\n",
        "\n",
        "    for _ in range(len(heap) - 1):\n",
        "        lowest = heapq.heappop(heap)\n",
        "        highest = heapq.heappop(heap)\n",
        "\n",
        "        for pair in lowest[1:]:\n",
        "            pair[1] = '0' + pair[1]\n",
        "        for pair in highest[1:]:\n",
        "            pair[1] = '1' + pair[1]\n",
        "\n",
        "        heapq.heappush(heap, [lowest[0] + highest[0]] + lowest[1:] + highest[1:])\n",
        "\n",
        "    return sorted(heapq.heappop(heap)[1:], key=lambda p: (len(p[-1]), p))\n",
        "\n",
        "# Step 3: Generate Huffman Codes\n",
        "def generate_huffman_codes(tree):\n",
        "    return {symbol: code for symbol, code in tree}\n",
        "\n",
        "# Step 4: Encode the Data\n",
        "def huffman_encoding(data, codes):\n",
        "    encoded_data = ''\n",
        "\n",
        "    for val in data.flatten():\n",
        "        encoded_data += codes[val]\n",
        "\n",
        "    return encoded_data\n",
        "\n",
        "# Example usage with quantized data\n",
        "frequency_table = calculate_frequency(quantized_medium_quality)\n",
        "huffman_tree = construct_huffman_tree(frequency_table)\n",
        "huffman_codes = generate_huffman_codes(huffman_tree)\n",
        "encoded_data = huffman_encoding(quantized_medium_quality, huffman_codes)\n",
        "\n",
        "\n",
        "# The `encoded_data` is now the Huffman encoded string of the quantized data\n"
      ],
      "metadata": {
        "id": "olJnC_9rXKPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_data_to_file(data, file_path):\n",
        "    # Write the data to the file\n",
        "    with open(file_path, 'w') as file:\n",
        "        file.write(data)\n",
        "\n",
        "compressed_data_path = \"/content/huffman_compress.txt\"\n",
        "save_data_to_file(encoded_data, compressed_data_path)\n"
      ],
      "metadata": {
        "id": "ndeuHbOYeiKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Create a Reverse Lookup Table from Huffman Codes\n",
        "def create_reverse_lookup_table(huffman_codes):\n",
        "    return {code: symbol for symbol, code in huffman_codes.items()}\n",
        "\n",
        "# Step 2: Decode the Encoded Data\n",
        "def huffman_decode(encoded_data, lookup_table):\n",
        "    decoded_values = []\n",
        "    current_code = \"\"\n",
        "    for bit in encoded_data:\n",
        "        current_code += bit\n",
        "        if current_code in lookup_table:\n",
        "            decoded_values.append(lookup_table[current_code])\n",
        "            current_code = \"\"\n",
        "    return decoded_values\n",
        "\n",
        "# Example usage\n",
        "reverse_lookup_table = create_reverse_lookup_table(huffman_codes)\n",
        "decoded_values = huffman_decode(encoded_data, reverse_lookup_table)\n",
        "\n",
        "# Convert the list of values back to the original shape (quantized image shape)\n",
        "decoded_image = np.array(decoded_values).reshape(quantized_medium_quality.shape)\n"
      ],
      "metadata": {
        "id": "6ikBsxizfRn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.fftpack import idct\n",
        "\n",
        "# Function to perform Inverse Quantization with a while loop\n",
        "def inverse_quantization(quantized_blocks, quality_factor=1):\n",
        "    scaled_quantization_matrix = custom_quantization_matrix * quality_factor\n",
        "    height, width = quantized_blocks.shape\n",
        "    inverse_quantized_blocks = np.zeros_like(quantized_blocks)\n",
        "\n",
        "    i = 0\n",
        "    while i < height:\n",
        "        j = 0\n",
        "        while j < width:\n",
        "            block = quantized_blocks[i:i+8, j:j+8]\n",
        "            inverse_quantized_block = block * scaled_quantization_matrix\n",
        "            inverse_quantized_blocks[i:i+8, j:j+8] = inverse_quantized_block\n",
        "            j += 8\n",
        "        i += 8\n",
        "\n",
        "    return inverse_quantized_blocks\n",
        "\n",
        "# Function to apply 2D IDCT to blocks of image with a while loop\n",
        "def apply_inverse_dct_to_blocks(dct_blocks, block_size=8):\n",
        "    height, width = dct_blocks.shape\n",
        "    idct_blocks = np.zeros_like(dct_blocks)\n",
        "\n",
        "    i = 0\n",
        "    while i < height:\n",
        "        j = 0\n",
        "        while j < width:\n",
        "            block = dct_blocks[i:i+block_size, j:j+block_size]\n",
        "            idct_block = idct(idct(block.T, norm='ortho').T, norm='ortho')\n",
        "            idct_blocks[i:i+block_size, j:j+block_size] = idct_block\n",
        "            j += block_size\n",
        "        i += block_size\n",
        "\n",
        "    return idct_blocks\n",
        "\n",
        "# Perform Inverse Quantization\n",
        "inverse_quantized_image = inverse_quantization(decoded_image, quality_factor=1)\n",
        "\n",
        "# Perform Inverse DCT\n",
        "reconstructed_image = apply_inverse_dct_to_blocks(inverse_quantized_image)\n",
        "\n",
        "# Clip the values to get valid pixel range (0-255) and convert to integers\n",
        "reconstructed_image = np.clip(reconstructed_image, 0, 255).astype(np.uint8)\n"
      ],
      "metadata": {
        "id": "bDuR-fK9gLgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reconstructed_image"
      ],
      "metadata": {
        "id": "WDQuOevYgpTu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "b8accc6d-c2da-4a6d-d4fa-a3301da4b45f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'reconstructed_image' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-6d63c00a86e1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreconstructed_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'reconstructed_image' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get reconstructed image**"
      ],
      "metadata": {
        "id": "AeOIB9tjqsKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'decoded_image' is the result of the decoding process\n",
        "\n",
        "# Step 1: Inverse Quantization\n",
        "inverse_quantized_result = inverse_quantization(decoded_image, quality_factor=1)  # Adjust quality factor if necessary\n",
        "\n",
        "# Step 2: Inverse Discrete Cosine Transform (IDCT)\n",
        "reconstructed_result = apply_inverse_dct_to_blocks(inverse_quantized_result)\n",
        "\n",
        "# Step 3: Clip pixel values to ensure they are within the valid range of 0-255\n",
        "clipped_reconstructed_result = np.clip(reconstructed_result, 0, 255).astype(np.uint8)\n",
        "\n",
        "# Step 4: Visualize the reconstructed image\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(clipped_reconstructed_result, cmap='gray')\n",
        "plt.title(\"Reconstructed Image\")\n",
        "plt.axis('off')  # Hide the axis for better visualization\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "ZU-kizmYgsqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import io\n",
        "import heapq\n",
        "from collections import defaultdict\n",
        "from scipy.fftpack import dct, idct\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Utility Functions\n",
        "def load_image_grayscale(image_path):\n",
        "    with Image.open(image_path) as img:\n",
        "        return np.array(img.convert('L'), dtype=np.float64)\n",
        "\n",
        "def compute_psnr(img1, img2):\n",
        "    mse = np.mean((img1 - img2) ** 2)\n",
        "    max_pixel = 255.0\n",
        "    psnr = 20 * np.log10(max_pixel / np.sqrt(mse))\n",
        "    return psnr\n",
        "\n",
        "def apply_dct_quantize(image, scale_factor):\n",
        "    # Apply 2D DCT to the entire image\n",
        "    dct_image = apply_dct_to_blocks(image)\n",
        "\n",
        "    # Quantize DCT coefficients based on a custom quantization matrix and scale factor\n",
        "    quantized_image = custom_quantize_dct_blocks(dct_image, scale_factor)\n",
        "\n",
        "    return quantized_image\n",
        "    # ...\n",
        "def huffman_encode(data):\n",
        "    # Step 1: Calculate frequency of each value in the data\n",
        "    frequency_table = calculate_frequency(data)\n",
        "\n",
        "    # Step 2: Construct Huffman tree\n",
        "    huffman_tree = construct_huffman_tree(frequency_table)\n",
        "\n",
        "    # Step 3: Generate Huffman codes\n",
        "    huffman_codes = generate_huffman_codes(huffman_tree)\n",
        "\n",
        "    # Step 4: Encode the data using Huffman codes\n",
        "    encoded_data = huffman_encoding(data, huffman_codes)\n",
        "\n",
        "    return encoded_data\n",
        "\n",
        "def estimate_bitrate(encoded_data):\n",
        "    buffer = io.BytesIO()\n",
        "    buffer.write(encoded_data.encode())\n",
        "    return buffer.tell() * 8\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def find_optimal_scaling(image, target_rate):\n",
        "    scale = 2.0\n",
        "    step = 0.2\n",
        "    best_psnr, best_scale = 0, scale\n",
        "    target_reached = False\n",
        "\n",
        "    while not target_reached:\n",
        "        quantized = apply_dct_quantize(image, scale)\n",
        "        encoded = huffman_encode(quantized)\n",
        "        bitrate = estimate_bitrate(encoded)\n",
        "        if bitrate < target_rate:\n",
        "            scale -= step\n",
        "        elif bitrate > target_rate:\n",
        "            scale += step\n",
        "        else:\n",
        "            target_reached = True\n",
        "\n",
        "        # Assuming a function 'inverse_process' to decode and reconstruct the image\n",
        "        # reconstructed = inverse_process(encoded)\n",
        "        psnr = compute_psnr(image, clipped_reconstructed_result)\n",
        "        print('Bitrate',bitrate,' Scale',scale)\n",
        "\n",
        "\n",
        "        if psnr > best_psnr:\n",
        "            best_psnr, best_scale = psnr, scale\n",
        "        if scale <= 0.5 or scale > 5.3:\n",
        "            break\n",
        "\n",
        "\n",
        "    return scale, best_psnr, encoded\n",
        "\n",
        "# Main Execution\n",
        "image_path = '/content/gray_image.jpg'\n",
        "E_No = 182\n",
        "target_bitrate = (E_No + 300) * 1000 * 1024\n",
        "image = load_image_grayscale(image_path)\n",
        "# Define the compression rate as 2%\n",
        "compression_rate = 0.02\n",
        "\n",
        "# Calculate the target bitrate based on the compression rate\n",
        "target_bitrate_2_percent = target_bitrate * compression_rate\n",
        "scale, psnr, encoded_data = find_optimal_scaling(image, target_bitrate_2_percent)\n",
        "print(f\"Optimal Scale: {scale}, Best PSNR: {psnr}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "m6ekdY9Wj5Ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gqxAoVOvm72J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}